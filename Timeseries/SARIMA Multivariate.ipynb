{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA stands for seasonal arima.it is family of box jenkin method. ARIMA has 3 differnt component together which is basically AR ( Auto regressive), MA( Moving average ) and I ( Integrating factor). Seasonal arima works like arima model but it has separate component to learn seasonality. seasonal arima has six hyperparameter p,d,q and P,D,Q which basically stands for AR,MA and intergating factor. later 3 terms is useful for seasonal factor. We can add external driver as well by exog and endog parameter.\n",
    "\n",
    "Import all the requires packages. we are using statsmodel 0.10.0 latest stable version.need to be cautious while using date time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the packages...\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dateutil import relativedelta\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data from excel file. we can add up workbook sheet as well in which we can import multiple sheets but here as single sheet is required hence directly read_excel works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('wholesaler_quarterly.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PayerCode</th>\n",
       "      <th>Volumn</th>\n",
       "      <th>avg_T</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>Selling_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.207000e+03</td>\n",
       "      <td>7207.000000</td>\n",
       "      <td>7207.000000</td>\n",
       "      <td>7207.000000</td>\n",
       "      <td>7207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.001022e+07</td>\n",
       "      <td>7570.700051</td>\n",
       "      <td>60.975458</td>\n",
       "      <td>3.498601</td>\n",
       "      <td>24.685861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.974866e+03</td>\n",
       "      <td>12573.282372</td>\n",
       "      <td>14.107479</td>\n",
       "      <td>1.928127</td>\n",
       "      <td>1.089576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000051e+07</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>34.975083</td>\n",
       "      <td>0.380425</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000523e+07</td>\n",
       "      <td>1826.147000</td>\n",
       "      <td>46.720930</td>\n",
       "      <td>1.693318</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.001100e+07</td>\n",
       "      <td>3585.606000</td>\n",
       "      <td>66.109886</td>\n",
       "      <td>3.674524</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.001494e+07</td>\n",
       "      <td>7646.167500</td>\n",
       "      <td>76.745568</td>\n",
       "      <td>5.597903</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.001854e+07</td>\n",
       "      <td>135616.949000</td>\n",
       "      <td>82.476560</td>\n",
       "      <td>7.411308</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PayerCode         Volumn        avg_T  precipitation  Selling_days\n",
       "count  7.207000e+03    7207.000000  7207.000000    7207.000000   7207.000000\n",
       "mean   3.001022e+07    7570.700051    60.975458       3.498601     24.685861\n",
       "std    4.974866e+03   12573.282372    14.107479       1.928127      1.089576\n",
       "min    3.000051e+07      -0.090000    34.975083       0.380425     19.000000\n",
       "25%    3.000523e+07    1826.147000    46.720930       1.693318     24.000000\n",
       "50%    3.001100e+07    3585.606000    66.109886       3.674524     24.000000\n",
       "75%    3.001494e+07    7646.167500    76.745568       5.597903     26.000000\n",
       "max    3.001854e+07  135616.949000    82.476560       7.411308     27.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['VLC_vl'] = df['VLC']/df['Volume']\n",
    "# X=df[['Date','Key','VLC_BGTRATE','VLC_vl']]\n",
    "# df = X.copy()\n",
    "#df = df[['Key','Date','Volume','avg_T','precipitation','PMI','Inflation_Rate','Selling_days_ratio']]\n",
    "df.rename(columns={'PayerCode':'Key'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df['Brand Family'] == 'BUD']\n",
    "# df.drop(columns=['Brand Family'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=df[['Date','Key','Volume','Selling_days','avg_T','precipitation','Consumer_Price_Index_month',\n",
    "#       'Real_GDP_lcu_quarter','Unemployment_Rate_quarter','BGT_Volume']]\n",
    "\n",
    "#X=df[['Date','Key','NR_Vol','VIC_Vol','VLC_Vol','MACO_Vol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[['Date','Key','Volume','avg_T','precipitation','Industrial_Production_Index_month','Unemployment_Rate_quarter',\n",
    "#          'Terms_of_Trade_annual','Exchange_Rate_Index_Period_Average_month','Exchange_Rate_LCU_per_US_Period_Average_month',\n",
    "#         'Real_Consumption_Per_Capita_US_quarter','Wholesale_Producer_Price_Index_LCU_basus_month','Nominal_Private_Consumption_lcu_quarter',\n",
    "#         'Consumer_Price_Index_month','Nominal_GDP_Per_Capita_US_quarter']]\n",
    "\n",
    "#Sarima with leave and volume drivers..\n",
    "#X = df[['Date','Key','Volume','GTO_Vol','Disc_Vol']]\n",
    "\n",
    "\n",
    "# X = pd.concat([X,df[['Industrial_Production_Index_month','Unemployment_Rate_quarter','Terms_of_Trade_annual',\n",
    "#                     'Consumer_Price_Index_month','Nominal_GDP_Per_Capita_US_quarter']]],axis=1)\n",
    "\n",
    "#X = pd.concat([X,df[['Nominal_GDP_Per_Capita_US_quarter']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holiday variables....\n",
    "# X = pd.concat([X,df.iloc[:,697:]],axis=1)\n",
    "# X = pd.concat([X,df.iloc[:,84:]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.pivot_table(df,index='Key',values=['NR_Vol','VIC_Vol','VLC_Vol','MACO_Vol'],aggfunc=['min','mean',np.median,'max']).T\n",
    "#pd.pivot(df,columns='Key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['qtr_year'] = df.Date.dt.quarter.astype(\"str\")+str(\"_\")+df.Date.dt.year.astype(\"str\")\n",
    "# tmp = df.groupby(by=['Key','qtr_year'])['BGT_Volume'].sum()\n",
    "# tmp = pd.DataFrame(tmp)\n",
    "# tmp.columns = ['BGT_qtr_Vol']\n",
    "# tmp.reset_index(inplace=True)\n",
    "# df = pd.merge(df,tmp,how='left',on=['Key','qtr_year'])\n",
    "# df.drop(columns=['qtr_year'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['year'] = df.Date.dt.year\n",
    "# tmp = df.groupby(by=['Key','year'])['BGT_Volume'].sum()\n",
    "# tmp = pd.DataFrame(tmp)\n",
    "# tmp.columns = ['BGT_year_Vol']\n",
    "# tmp.reset_index(inplace=True)\n",
    "# df = pd.merge(df,tmp,how='left',on=['Key','year'])\n",
    "# df.drop(columns=['year'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['qtr'] = df.Date.dt.quarter\n",
    "# df['month'] = df.Date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bgt_transformation(brand_df):\n",
    "#     brand_df['qtr_year'] = brand_df.Date.dt.quarter.astype(str)+str(\"_\")+brand_df.Date.dt.year.astype(str)\n",
    "#     brand_df['cum_sum_bgt_qtr'] = brand_df.groupby(by=['qtr_year'])['BGT_Volume'].cumsum()\n",
    "#     brand_df['BGT_qtr_ratio']= brand_df['cum_sum_bgt_qtr'].divide(brand_df['BGT_qtr_Vol'])\n",
    "#     brand_df['cum_sum_vol_qtr'] = brand_df.groupby(by=['qtr_year'])['Volume'].cumsum()\n",
    "#     brand_df['cum_sum_vol_qtr_shift'] = brand_df['cum_sum_vol_qtr'].shift(1)\n",
    "#     brand_df.loc[((brand_df.month==1)|(brand_df.month==4)|(brand_df.month==7)|(brand_df.month==10)),'cum_sum_vol_qtr_shift'] = 0\n",
    "#     brand_df['bgt_diff_till_month'] = brand_df['BGT_qtr_Vol'] - brand_df['cum_sum_vol_qtr_shift']\n",
    "#     brand_df.drop(columns=['qtr_year','cum_sum_bgt_qtr','cum_sum_vol_qtr','cum_sum_vol_qtr_shift'],inplace=True)\n",
    "#     return brand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date column in datetime format as we have to create index as datetime format only. be careful while giving format of date as it might change later operations. get the unique brand list as we have to iterate over all the brands separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date = pd.to_datetime(df.Date,format='%d-%m-%Y')\n",
    "#Brand_list = ['BUD','DFH','GSB','HBBP','HBI','HBO','HKOW','ISP','OTH','SED']\n",
    "#Brand_list = df.Key.unique()\n",
    "Brand_list = [30000514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30000514]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,brand_key in enumerate(Brand_list):\n",
    "#     Brand_list[i] = Brand_list[i].replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand_list = ['BUD_ALU_Anhui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For modelling we follow differnt steps:\n",
    "1. iterate over all brands and take out single brand each time.\n",
    "2. provide train and test date based on requirement.\n",
    "3. divide train and test data as le cycle works for whole year. ex apr is start so (3+9,4+8 etc..) each time upto december we have to complete, start date could be any.\n",
    "4. iterate over p,d,q and P,D,Q value. provide min and max value which basically decide by ACF and PACF lag.\n",
    "5. compare the aic and bic value and select least one. As least aic is best.\n",
    "6. foorecast for the aic value\n",
    "7. forecast for required no of steps ( basically ahead month or year based on freuqency).\n",
    "8. save the result and iterate till end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUD\n",
      "2019-04-01 00:00:00\n",
      "              avg_T  precipitation      PMI  Inflation_Rate  \\\n",
      "Date                                                          \n",
      "2019-04-01 62.51758        3.67452 50.10000         2.50000   \n",
      "\n",
      "            Selling_days_ratio  \n",
      "Date                            \n",
      "2019-04-01             0.83333  \n",
      "2019-05-01 00:00:00\n",
      "              avg_T  precipitation      PMI  Inflation_Rate  \\\n",
      "Date                                                          \n",
      "2019-05-01 69.70219        4.22272 49.40000         2.70000   \n",
      "\n",
      "            Selling_days_ratio  \n",
      "Date                            \n",
      "2019-05-01             0.77419  \n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame(columns=[\"Brand\",\"Forecast_values\",\"Actual_values\"])\n",
    "for brand_name in Brand_list:\n",
    "    print(brand_name)\n",
    "    brand_df = df.loc[df.Key == brand_name]\n",
    "    #brand_df = bgt_transformation(brand_df)\n",
    "    brand_df.set_index('Date',inplace=True)\n",
    "    tmp = []\n",
    "    forecast = pd.DataFrame()\n",
    "    Actuals = pd.DataFrame()\n",
    "    #brand_df = brand_df[:'2019-12-01']\n",
    "    s = pd.DataFrame()\n",
    "    k = pd.DataFrame()\n",
    "    \n",
    "    if len(brand_df)>12:\n",
    "        train_start = datetime.date(2019,1, 1)\n",
    "        train_till = datetime.date(2019, 7, 1)\n",
    "        Actuals_end = datetime.date(2020, 1, 1)\n",
    "        train_date = train_start\n",
    "        while train_date < train_till:\n",
    "            test_date = train_date + relativedelta.relativedelta(months=1)\n",
    "            dependent_colume = 'Volume'\n",
    "            x = brand_df.drop(columns=[dependent_colume,'Key'])\n",
    "            y = brand_df[[dependent_colume]]\n",
    "            train_x = x[:train_date]\n",
    "            train_y = y[:train_date][[dependent_colume]]\n",
    "            test_x = x[test_date:]\n",
    "            test_y = y[test_date:][[dependent_colume]]\n",
    "            train_date = train_date + relativedelta.relativedelta(months=3)\n",
    "\n",
    "            if ((test_date.month == 8) or (test_date.month == 2)):\n",
    "                print(\"July imputation...\")\n",
    "                train_y[train_date:train_date] = np.nan\n",
    "\n",
    "            p = d= q = range(0,2)\n",
    "            # generate p,d,q value between 0 and 2\n",
    "            pdq = list(itertools.product(p, d, q))\n",
    "            seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "            pdq_list = {}\n",
    "            spdq_list = {}\n",
    "            aic_value = {}\n",
    "            flag = 0\n",
    "            for param in pdq:\n",
    "                for param_seasonal in seasonal_pdq:\n",
    "                    try:\n",
    "                        mod = SARIMAX(exog=train_x,\n",
    "                                      endog=train_y,\n",
    "                                      order=param,\n",
    "                                      seasonal_order=param_seasonal,\n",
    "                                      enforce_stationarity=True,\n",
    "                                      enforce_invertibility=True)\n",
    "\n",
    "                        results = mod.fit()\n",
    "                        if flag == 0:\n",
    "                            aic_value['aic'] = results.aic\n",
    "                            pdq_list['pdq'] = param\n",
    "                            spdq_list['spdq_list'] = param_seasonal\n",
    "                        else :\n",
    "                            #check for least aic value and store pdq and seasonal parameters...\n",
    "                            if aic_value['aic'] > results.aic :\n",
    "                                aic_value['aic'] = results.aic\n",
    "                                pdq_list['pdq'] = param\n",
    "                                spdq_list['spdq_list'] = param_seasonal\n",
    "                        flag = flag + 1\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "            #run sarima by best combination of parameters...\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(exog=train_x,\n",
    "                                                endog=train_y,\n",
    "                                                order=pdq_list['pdq'],\n",
    "                                                seasonal_order=spdq_list['spdq_list'],\n",
    "                                                enforce_stationarity=True,\n",
    "                                                enforce_invertibility=True)\n",
    "                results = mod.fit()\n",
    "        #         #forecast for next month....\n",
    "                if test_date > Actuals_end:\n",
    "                    s = pd.DataFrame()\n",
    "                    s[\"Forecast_values\"] = list(results.get_prediction(exog=test_x[test_date:],start=test_x.index.min(),end=test_x.index.max()).predicted_mean.values)\n",
    "                    s.index = test_y[test_date:].index\n",
    "                    s[\"Brand\"] = str(brand_name) +str(\"_\")+ s.index.month.astype(str) +str(\"_\")+s.index.year.astype(str)\n",
    "\n",
    "\n",
    "                    k = pd.DataFrame()\n",
    "                    k = test_y[test_date:]\n",
    "                    k.columns = ['Actual_values']\n",
    "                    k.index = test_y[test_date:].index\n",
    "                    k[\"Brand\"] = str(brand_name) +str(\"_\")+ k.index.month.astype(str) +str(\"_\")+k.index.year.astype(str)\n",
    "                    break\n",
    "                \n",
    "                print(test_x.index.min())\n",
    "                print(test_x[test_date:test_date])\n",
    "                forecast[str(brand_name)+str('_')+str(test_date.month)+str(\"_\")+str(test_date.year)] = results.get_prediction(exog=test_x[test_date:test_date],\n",
    "                                                                                            start=test_x.index.min()).predicted_mean.values\n",
    "                Actuals[str(brand_name)+str('_')+str(test_date.month)+str(\"_\")+str(test_date.year)] = test_y[test_date:test_date].values[0]\n",
    "           \n",
    "            except Exception as e:\n",
    "                print(\"in exception\")\n",
    "                continue\n",
    "        \n",
    "        if ((len(forecast)>0) & (len(Actuals)>0)):\n",
    "            forecast=forecast.T.reset_index()\n",
    "            forecast.columns=[\"Brand\",\"Forecast_values\"]\n",
    "            if(len(s)>0):\n",
    "                forecast= pd.concat([forecast,s],axis=0)\n",
    "            Actuals=Actuals.T.reset_index()\n",
    "            Actuals.columns=[\"Brand\",\"Actual_values\"]\n",
    "            if(len(k)>0):\n",
    "                Actuals= pd.concat([Actuals,k],axis=0)\n",
    "            brand_wise_merge = forecast.merge(Actuals,on=\"Brand\",how=\"left\")\n",
    "            final = final.append(brand_wise_merge,ignore_index=True)\n",
    "        else:\n",
    "            print(\"No forecast\")\n",
    "    else:\n",
    "        print(\"length mismatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Forecast_values</th>\n",
       "      <th>Actual_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUD_4_2019</td>\n",
       "      <td>1825638.94175</td>\n",
       "      <td>1526338.82912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUD_5_2019</td>\n",
       "      <td>2097858.27822</td>\n",
       "      <td>2070232.41412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand  Forecast_values  Actual_values\n",
       "0  BUD_4_2019    1825638.94175  1526338.82912\n",
       "1  BUD_5_2019    2097858.27822  2070232.41412"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the accuracy which is mape (1- ABS(actual-forcast)/actual). we use mape as it is unit less and later can multiply with 100 so we can get results in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Error']=np.abs(final['Actual_values']-final['Forecast_values'])\n",
    "final[['Brandname','leMonth','leYear']] = final.Brand.str.split(\"_\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_accuracy = final.groupby(by=['leMonth','leYear']).sum()[['Error','Actual_values','Forecast_values']]\n",
    "Agg_accuracy['Accuracy'] = np.round((1-(Agg_accuracy['Error']/Agg_accuracy['Actual_values']))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_accuracy_brand = final.groupby(by=['Brandname']).sum()[['Error','Actual_values','Forecast_values']]\n",
    "Agg_accuracy_brand['Accuracy'] = np.round((1-(Agg_accuracy_brand['Error']/Agg_accuracy_brand['Actual_values']))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Error</th>\n",
       "      <th>Actual_values</th>\n",
       "      <th>Forecast_values</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leMonth</th>\n",
       "      <th>leYear</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2020</th>\n",
       "      <td>8.373235e+04</td>\n",
       "      <td>2.165093e+06</td>\n",
       "      <td>2.081361e+06</td>\n",
       "      <td>96.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>2019</th>\n",
       "      <td>1.830805e+05</td>\n",
       "      <td>1.228504e+06</td>\n",
       "      <td>1.411585e+06</td>\n",
       "      <td>85.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.005060e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.005060e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11</th>\n",
       "      <th>2019</th>\n",
       "      <td>1.574344e+05</td>\n",
       "      <td>1.187562e+06</td>\n",
       "      <td>1.344997e+06</td>\n",
       "      <td>86.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>9.021242e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.021242e+05</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">12</th>\n",
       "      <th>2019</th>\n",
       "      <td>2.583010e+03</td>\n",
       "      <td>1.196691e+06</td>\n",
       "      <td>1.194108e+06</td>\n",
       "      <td>99.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>8.498954e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.498954e+05</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2020</th>\n",
       "      <td>1.096673e+06</td>\n",
       "      <td>1.749663e+05</td>\n",
       "      <td>1.271639e+06</td>\n",
       "      <td>-526.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2020</th>\n",
       "      <td>8.848868e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.848868e+05</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>2019</th>\n",
       "      <td>2.993001e+05</td>\n",
       "      <td>1.526339e+06</td>\n",
       "      <td>1.825639e+06</td>\n",
       "      <td>80.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.312857e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.312857e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>2019</th>\n",
       "      <td>2.762586e+04</td>\n",
       "      <td>2.070232e+06</td>\n",
       "      <td>2.097858e+06</td>\n",
       "      <td>98.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.910922e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.910922e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>2019</th>\n",
       "      <td>2.848402e+05</td>\n",
       "      <td>2.367853e+06</td>\n",
       "      <td>2.083013e+06</td>\n",
       "      <td>87.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2.132445e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.132445e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>2019</th>\n",
       "      <td>5.510126e+05</td>\n",
       "      <td>1.748441e+06</td>\n",
       "      <td>2.299453e+06</td>\n",
       "      <td>68.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.488841e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.488841e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>2019</th>\n",
       "      <td>3.054122e+05</td>\n",
       "      <td>1.965172e+06</td>\n",
       "      <td>1.659760e+06</td>\n",
       "      <td>84.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.738964e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.738964e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>2019</th>\n",
       "      <td>1.998547e+05</td>\n",
       "      <td>1.677322e+06</td>\n",
       "      <td>1.877176e+06</td>\n",
       "      <td>88.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.330234e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.330234e+06</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Error  Actual_values  Forecast_values  Accuracy\n",
       "leMonth leYear                                                        \n",
       "1       2020    8.373235e+04   2.165093e+06     2.081361e+06     96.13\n",
       "10      2019    1.830805e+05   1.228504e+06     1.411585e+06     85.10\n",
       "        2020    1.005060e+06   0.000000e+00     1.005060e+06      -inf\n",
       "11      2019    1.574344e+05   1.187562e+06     1.344997e+06     86.74\n",
       "        2020    9.021242e+05   0.000000e+00     9.021242e+05      -inf\n",
       "12      2019    2.583010e+03   1.196691e+06     1.194108e+06     99.78\n",
       "        2020    8.498954e+05   0.000000e+00     8.498954e+05      -inf\n",
       "2       2020    1.096673e+06   1.749663e+05     1.271639e+06   -526.79\n",
       "3       2020    8.848868e+05   0.000000e+00     8.848868e+05      -inf\n",
       "4       2019    2.993001e+05   1.526339e+06     1.825639e+06     80.39\n",
       "        2020    1.312857e+06   0.000000e+00     1.312857e+06      -inf\n",
       "5       2019    2.762586e+04   2.070232e+06     2.097858e+06     98.67\n",
       "        2020    1.910922e+06   0.000000e+00     1.910922e+06      -inf\n",
       "6       2019    2.848402e+05   2.367853e+06     2.083013e+06     87.97\n",
       "        2020    2.132445e+06   0.000000e+00     2.132445e+06      -inf\n",
       "7       2019    5.510126e+05   1.748441e+06     2.299453e+06     68.49\n",
       "        2020    1.488841e+06   0.000000e+00     1.488841e+06      -inf\n",
       "8       2019    3.054122e+05   1.965172e+06     1.659760e+06     84.46\n",
       "        2020    1.738964e+06   0.000000e+00     1.738964e+06      -inf\n",
       "9       2019    1.998547e+05   1.677322e+06     1.877176e+06     88.08\n",
       "        2020    1.330234e+06   0.000000e+00     1.330234e+06      -inf"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final[['Brand','Month']] = final.Brand.str.split(\"_\",expand=True) \n",
    "# print(final)\n",
    "# final['Error']=np.abs(final['Forecast_values']-final['Actual_values'])\n",
    "# final_2=final.groupby(by=['Month','Brand'])['Error',\"Actual_values\"].sum().reset_index()\n",
    "# final_2['Error_perc']=final_2['Error']/final_2['Actual_values']\n",
    "# print(final_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel('./SARIMA/sarima_Brand_pmi_inflation_seldayratio_temp_prec_Vol.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = pd.DataFrame(columns=[\"Brand\",\"Forecast_values\",\"Actual_values\"])\n",
    "# for brand_name in Brand_list:\n",
    "#     print(brand_name)\n",
    "#     brand_df = df.loc[df.Key == brand_name]\n",
    "#    # brand_df = bgt_transformation(brand_df)\n",
    "#     brand_df.set_index('Date',inplace=True)\n",
    "#     tmp = []\n",
    "#     forecast = pd.DataFrame()\n",
    "#     Actuals = pd.DataFrame()\n",
    "#     brand_df = brand_df[:'2019-12-01']\n",
    "    \n",
    "#     if len(brand_df)>12:\n",
    "#         for i in range(9,0,-1):\n",
    "#             train_date = brand_df.index.max() - relativedelta.relativedelta(months=i)\n",
    "#             test_date = train_date + relativedelta.relativedelta(months=1)\n",
    "            \n",
    "#             dependent_colume = 'Volume'\n",
    "#             x = brand_df.drop(columns=[dependent_colume,'Key'])\n",
    "#             y = brand_df[[dependent_colume]]\n",
    "#             train_x = x[:train_date]\n",
    "#             train_y = y[:train_date][[dependent_colume]]\n",
    "#             test_x = x[test_date:test_date]\n",
    "#             test_y = y[test_date:test_date][[dependent_colume]]\n",
    "\n",
    "#             if (test_date.month == 8):\n",
    "#                 print(\"July imputation...\")\n",
    "#                 train_y[train_date:train_date] = np.nan\n",
    "\n",
    "#             p = d= q = range(0,2)\n",
    "#             # generate p,d,q value between 0 and 2\n",
    "#             pdq = list(itertools.product(p, d, q))\n",
    "#             seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "#             pdq_list = {}\n",
    "#             spdq_list = {}\n",
    "#             aic_value = {}\n",
    "#             flag = 0\n",
    "#             for param in pdq:\n",
    "#                 for param_seasonal in seasonal_pdq:\n",
    "#                     try:\n",
    "#                         mod = SARIMAX(exog=train_x,\n",
    "#                                       endog=train_y,\n",
    "#                                       order=param,\n",
    "#                                       seasonal_order=param_seasonal,\n",
    "#                                       enforce_stationarity=True,\n",
    "#                                       enforce_invertibility=True)\n",
    "\n",
    "#                         results = mod.fit()\n",
    "#                         if flag == 0:\n",
    "#                             aic_value['aic'] = results.aic\n",
    "#                             pdq_list['pdq'] = param\n",
    "#                             spdq_list['spdq_list'] = param_seasonal\n",
    "#                         else :\n",
    "#                             #check for least aic value and store pdq and seasonal parameters...\n",
    "#                             if aic_value['aic'] > results.aic :\n",
    "#                                 aic_value['aic'] = results.aic\n",
    "#                                 pdq_list['pdq'] = param\n",
    "#                                 spdq_list['spdq_list'] = param_seasonal\n",
    "#                         flag = flag + 1\n",
    "#                     except:\n",
    "#                         continue\n",
    "\n",
    "#             #run sarima by best combination of parameters...\n",
    "#             try:\n",
    "#                 mod = sm.tsa.statespace.SARIMAX(exog=train_x,\n",
    "#                                                 endog=train_y,\n",
    "#                                                 order=pdq_list['pdq'],\n",
    "#                                                 seasonal_order=spdq_list['spdq_list'],\n",
    "#                                                 enforce_stationarity=True,\n",
    "#                                                 enforce_invertibility=True)\n",
    "#                 results = mod.fit()\n",
    "#         #         #forecast for next month....\n",
    "#                 print(results.get_prediction(exog=test_x[:test_date],start=test_x.index.min()).predicted_mean.values)\n",
    "#                 forecast[str(brand_name)+str(\"_\")+str(test_date.month)] = results.get_prediction(exog=test_x[:test_date],\n",
    "#                                                                                             start=test_x.index.min()).predicted_mean.values\n",
    "#                 Actuals[str(brand_name)+str(\"_\")+str(test_date.month)] = test_y[:test_date].values[0]\n",
    "#             except:\n",
    "#                 continue\n",
    "#         if (len(forecast)>0 & len(Actuals>0)):\n",
    "#             forecast=forecast.T.reset_index()\n",
    "#             forecast.columns=[\"Brand\",\"Forecast_values\"]\n",
    "#             Actuals=Actuals.T.reset_index()\n",
    "#             Actuals.columns=[\"Brand\",\"Actual_values\"]\n",
    "#             brand_wise_merge = forecast.merge(Actuals,on=\"Brand\",how=\"left\")\n",
    "#             final = final.append(brand_wise_merge,ignore_index=True)\n",
    "#         else:\n",
    "#             print(\"No forecast\")\n",
    "#     else:\n",
    "#         print(\"length mismatch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
